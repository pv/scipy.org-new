{
 "metadata": {},
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Kalman filtering\n",
      "======================================================================\n",
      "\n",
      "This is code implements the example given in pages 11-15 of [An\n",
      "Introduction to the Kalman\n",
      "Filter](http://www.cs.unc.edu/~welch/kalman/kalmanIntro.html) by Greg\n",
      "Welch and Gary Bishop, University of North Carolina at Chapel Hill,\n",
      "Department of Computer Science.\n",
      "\n",
      "It produces plots that look something like this:\n",
      "\n",
      "![](files/attachments/KalmanFiltering/estimate_vs_iteration.png) **Estimate vs. iteration step**\n",
      "\n",
      "![](files/attachments/KalmanFiltering/error_vs_iteration.png) **Estimated *a priori* error vs.\n",
      "iteration step**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Kalman filter example demo in Python\n",
      "\n",
      "# A Python implementation of the example given in pages 11-15 of \"An\n",
      "# Introduction to the Kalman Filter\" by Greg Welch and Gary Bishop,\n",
      "# University of North Carolina at Chapel Hill, Department of Computer\n",
      "# Science, TR 95-041,\n",
      "# http://www.cs.unc.edu/~welch/kalman/kalmanIntro.html\n",
      "\n",
      "# by Andrew D. Straw\n",
      "\n",
      "import numpy\n",
      "import pylab\n",
      "\n",
      "# intial parameters\n",
      "n_iter = 50\n",
      "sz = (n_iter,) # size of array\n",
      "x = -0.37727 # truth value (typo in example at top of p. 13 calls this z)\n",
      "z = numpy.random.normal(x,0.1,size=sz) # observations (normal about x, sigma=0.1)\n",
      "\n",
      "Q = 1e-5 # process variance\n",
      "\n",
      "# allocate space for arrays\n",
      "xhat=numpy.zeros(sz)      # a posteri estimate of x\n",
      "P=numpy.zeros(sz)         # a posteri error estimate\n",
      "xhatminus=numpy.zeros(sz) # a priori estimate of x\n",
      "Pminus=numpy.zeros(sz)    # a priori error estimate\n",
      "K=numpy.zeros(sz)         # gain or blending factor\n",
      "\n",
      "R = 0.1**2 # estimate of measurement variance, change to see effect\n",
      "\n",
      "# intial guesses\n",
      "xhat[0] = 0.0\n",
      "P[0] = 1.0\n",
      "\n",
      "for k in range(1,n_iter):\n",
      "    # time update\n",
      "    xhatminus[k] = xhat[k-1]\n",
      "    Pminus[k] = P[k-1]+Q\n",
      "    \n",
      "    # measurement update\n",
      "    K[k] = Pminus[k]/( Pminus[k]+R )\n",
      "    xhat[k] = xhatminus[k]+K[k]*(z[k]-xhatminus[k])\n",
      "    P[k] = (1-K[k])*Pminus[k]\n",
      "\n",
      "pylab.figure()\n",
      "pylab.plot(z,'k+',label='noisy measurements')\n",
      "pylab.plot(xhat,'b-',label='a posteri estimate')\n",
      "pylab.axhline(x,color='g',label='truth value')\n",
      "pylab.legend()\n",
      "pylab.xlabel('Iteration')\n",
      "pylab.ylabel('Voltage')\n",
      "\n",
      "pylab.figure()\n",
      "valid_iter = range(1,n_iter) # Pminus not valid at step 0\n",
      "pylab.plot(valid_iter,Pminus[valid_iter],label='a priori error estimate')\n",
      "pylab.xlabel('Iteration')\n",
      "pylab.ylabel('$(Voltage)^2$')\n",
      "pylab.setp(pylab.gca(),'ylim',[0,.01])\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}